----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1        [-1, 8, 1024, 2048]             224
       BatchNorm2d-2        [-1, 8, 1024, 2048]              16
              ReLU-3        [-1, 8, 1024, 2048]               0
            Conv2d-4        [-1, 8, 1024, 2048]             584
       BatchNorm2d-5        [-1, 8, 1024, 2048]              16
              ReLU-6        [-1, 8, 1024, 2048]               0
     UNetConvBlock-7        [-1, 8, 1024, 2048]               0
            Conv2d-8        [-1, 16, 512, 1024]           1,168
       BatchNorm2d-9        [-1, 16, 512, 1024]              32
             ReLU-10        [-1, 16, 512, 1024]               0
           Conv2d-11        [-1, 16, 512, 1024]           2,320
      BatchNorm2d-12        [-1, 16, 512, 1024]              32
             ReLU-13        [-1, 16, 512, 1024]               0
    UNetConvBlock-14        [-1, 16, 512, 1024]               0
           Conv2d-15         [-1, 32, 256, 512]           4,640
      BatchNorm2d-16         [-1, 32, 256, 512]              64
             ReLU-17         [-1, 32, 256, 512]               0
           Conv2d-18         [-1, 32, 256, 512]           9,248
      BatchNorm2d-19         [-1, 32, 256, 512]              64
             ReLU-20         [-1, 32, 256, 512]               0
    UNetConvBlock-21         [-1, 32, 256, 512]               0
           Conv2d-22         [-1, 64, 128, 256]          18,496
      BatchNorm2d-23         [-1, 64, 128, 256]             128
             ReLU-24         [-1, 64, 128, 256]               0
           Conv2d-25         [-1, 64, 128, 256]          36,928
      BatchNorm2d-26         [-1, 64, 128, 256]             128
             ReLU-27         [-1, 64, 128, 256]               0
    UNetConvBlock-28         [-1, 64, 128, 256]               0
           Conv2d-29         [-1, 128, 64, 128]          73,856
      BatchNorm2d-30         [-1, 128, 64, 128]             256
             ReLU-31         [-1, 128, 64, 128]               0
           Conv2d-32         [-1, 128, 64, 128]         147,584
      BatchNorm2d-33         [-1, 128, 64, 128]             256
             ReLU-34         [-1, 128, 64, 128]               0
    UNetConvBlock-35         [-1, 128, 64, 128]               0
  ConvTranspose2d-36         [-1, 64, 128, 256]          32,832
           Conv2d-37         [-1, 64, 128, 256]          73,792
      BatchNorm2d-38         [-1, 64, 128, 256]             128
             ReLU-39         [-1, 64, 128, 256]               0
           Conv2d-40         [-1, 64, 128, 256]          36,928
      BatchNorm2d-41         [-1, 64, 128, 256]             128
             ReLU-42         [-1, 64, 128, 256]               0
    UNetConvBlock-43         [-1, 64, 128, 256]               0
      UNetUpBlock-44         [-1, 64, 128, 256]               0
  ConvTranspose2d-45         [-1, 32, 256, 512]           8,224
           Conv2d-46         [-1, 32, 256, 512]          18,464
      BatchNorm2d-47         [-1, 32, 256, 512]              64
             ReLU-48         [-1, 32, 256, 512]               0
           Conv2d-49         [-1, 32, 256, 512]           9,248
      BatchNorm2d-50         [-1, 32, 256, 512]              64
             ReLU-51         [-1, 32, 256, 512]               0
    UNetConvBlock-52         [-1, 32, 256, 512]               0
      UNetUpBlock-53         [-1, 32, 256, 512]               0
  ConvTranspose2d-54        [-1, 16, 512, 1024]           2,064
           Conv2d-55        [-1, 16, 512, 1024]           4,624
      BatchNorm2d-56        [-1, 16, 512, 1024]              32
             ReLU-57        [-1, 16, 512, 1024]               0
           Conv2d-58        [-1, 16, 512, 1024]           2,320
      BatchNorm2d-59        [-1, 16, 512, 1024]              32
             ReLU-60        [-1, 16, 512, 1024]               0
    UNetConvBlock-61        [-1, 16, 512, 1024]               0
      UNetUpBlock-62        [-1, 16, 512, 1024]               0
  ConvTranspose2d-63        [-1, 8, 1024, 2048]             520
           Conv2d-64        [-1, 8, 1024, 2048]           1,160
      BatchNorm2d-65        [-1, 8, 1024, 2048]              16
             ReLU-66        [-1, 8, 1024, 2048]               0
           Conv2d-67        [-1, 8, 1024, 2048]             584
      BatchNorm2d-68        [-1, 8, 1024, 2048]              16
             ReLU-69        [-1, 8, 1024, 2048]               0
    UNetConvBlock-70        [-1, 8, 1024, 2048]               0
      UNetUpBlock-71        [-1, 8, 1024, 2048]               0
           Conv2d-72       [-1, 34, 1024, 2048]             306
================================================================
Total params: 487,586
Trainable params: 487,586
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 24.00
Forward/backward pass size (MB): 4440.00
Params size (MB): 1.86
Estimated Total Size (MB): 4465.86
----------------------------------------------------------------